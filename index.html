<!DOCTYPE HTML>
<!--
	Massively by HTML5 UP
	html5up.net | @ajlkn
	Free for personal and commercial use under the CCA 3.0 license (html5up.net/license)
-->
<html>
	
<!-- Mirrored from nonyej.github.io/ by HTTrack Website Copier/3.x [XR&CO'2014], Tue, 02 May 2023 21:05:47 GMT -->
<!-- Added by HTTrack --><meta http-equiv="content-type" content="text/html;charset=utf-8" /><!-- /Added by HTTrack -->
<head>
		<title>Data Scientist by day, Data Superhero by night.
		     </title>
		<meta charset="utf-8" />
		<meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no" />
		<link rel="stylesheet" href="assets/css/main.css" />
		<noscript><link rel="stylesheet" href="assets/css/noscript.css" /></noscript>
	</head>
	<body class="is-preload">

		<!-- Wrapper -->
			<div id="wrapper" class="fade-in">

				<!-- Intro -->
					<div id="intro">
						<h1>PORTFOLIO FOR<br />
						OLISEDEME CHINONYE FAVOUR</h1>
						<p>Hi there! Welcome to my space. I am a Data scientist with extensive experience working with data aggregators, building
							analytical, statistical processes and knowledge to deliver end to end data-technical projects.<a href="https://www.linkedin.com/in/olisedeme-chinonye-favour-542357108"> Say 'Hi' on LinkedIn  </a>.</p>
						<ul class="actions">
							<li><a href="#header" class="button icon solid solo fa-arrow-down scrolly">Continue</a></li>
						</ul>
					</div>

				<!-- Header -->
					<header id="header">
						<a href="index-2.html" class="logo">Data Projects</a>
					</header>

				<!-- Nav -->
					<nav id="nav">
						<ul class="links">
							<li class="active"><a href="index-2.html">Data Projects</a></li>
							<!-- <li><a href="generic.html">Generic Page</a></li>
							<li><a href="elements.html">Elements Reference</a></li> -->
						</ul>
						<ul class="icons">
							<li><a href="https://twitter.com/_NonyeOJ?t=XKpP13SXwC8lIZ2opfB1tQ&amp;s=03" class="icon brands fa-twitter"><span class="label">Twitter</span></a></li>
							<li><a href="#" class="icon brands fa-facebook-f"><span class="label">Facebook</span></a></li>
							<li><a href="#" class="icon brands fa-instagram"><span class="label">Instagram</span></a></li>
							<li><a href="https://github.com/NonyeJ" class="icon brands fa-github"><span class="label">GitHub</span></a></li>
						</ul>
					</nav>

				<!-- Main -->
					<div id="main">

						<!-- Tools Arsenal -->
							<article class="post featured">
								<header class="major">
									<h2><a href="#">My Tool 'Box'</a></h2>
									<p>Technology evolves really fast and we are constantly learning new ways to make work faster and more efficient.
									 As a Data Scientist, I work with the following:
									<li>Programming Language: Python, SQL & R.
									<li>Data Visualization: Power BI,Matplotlib,Seaborn,Tableau
									<li>Data Analysis: Microsoft Excel, SQL, Data Wrangling,Exploratory Data Analysis(Python)
									<li>Microsoft Power Platform: Microsoft Power Automate aka MS.Flow,Microsoft Power Apps,etc.
									<li>Deploy: Azure, etc.
									<p><p></p>Technology evolves and so do we.</p>
									<a href="https://drive.google.com/drive/folders/1vchtDEFhhYsdOH59dX7FXPCi-4EdFzCq?usp=sharing" class="button large">See my resume here <a href="https://www.linkedin.com/in/olisedeme-chinonye-favour-542357108"></a></li>
								</ul>
							</article>



						<!-- Featured Post -->
						<article class="post featured">
							<header class="major">
								<h2><a href="https://github.com/NonyeJ/D-S-Sales-Dashboard-using-Google-Data-Studio">Google Data Studio Visualization: D&S Health Sales Dashboard</h2> 
								    <p>The Google ecosystem is a fantastic innovation. It was my first go-to in my journey before I was swayed by Microsoft. For this simple analysis & Visualization, we highlight D&S Health Tech. D&S is a mental health tech-ed organization. D&S has just completed a sales campaign. The Sales team needs some insights(revenue,products,coupons,etc.) from some sales data submitted.
										This analysis and visulaization was done using Google Data Studio, while the dataset was collected on Google Sheets.
									
										.<p>
							</header>
							<a href="https://github.com/NonyeJ/D-S-Sales-Dashboard-using-Google-Data-Studio" class="image main"><img src="images/ezgif.com-gif-maker.png" alt="" /></a>
							<ul class="actions special">
								<li></li><a href="https://datastudio.google.com/reporting/a6c34151-7341-408f-8752-b8ef96b022bb" class="button small">View Interactive Dashboard</a></li>
								<li></li><a href="https://docs.google.com/spreadsheets/d/1NOAJeyiBSvfBm76TSxZVCIQDvnuWaz3_vLMUncbCwQc/edit?usp=sharing" class="button small">View Google Sheets</a></li>
								
							
								<p><li><a href="https://github.com/NonyeJ/D-S-Sales-Dashboard-using-Google-Data-Studio" class="button small">View Project</a>
							</ul>
						</article>		
						<!-- Featured Post -->
						<article class="post featured">
							<header class="major">
								<h2><a href="https://github.com/NonyeJ/Google-Stocks-Time-Series-Forecasting-with-SARIMA-Model">Time Series Forecasting with SARIMA Model</h2>(Google Stocks,Yfinance API,Matplotlib,etc.)</a></a>
								    <p>ARIMA is an acronym that stands for AutoRegressive Integrated Moving Average. This is one of the easiest and effective machine learning algorithm to performing time series forecasting. This is the combination of Auto Regression and Moving average.
									    ARIMA is an algorithm used for forecasting Time Series Data. Using this model, we can analyze and model time-series data to make future decisions. 
										Some of the applications of Time Series Forecasting are weather forecasting, sales forecasting, business forecasting, stock price forecasting,etc 
										For stationary data, ARIMA model is required; seasonal data, Seasonal ARIMA (SARIMA) is required . 
									
										.<p>
							</header>
							<a href="https://github.com/NonyeJ/Google-Stocks-Time-Series-Forecasting-with-SARIMA-Model" class="image main"><img src="images/Time%20Series%20Forecasting%20with%20SARIMA%20Model.jpg" alt="" /></a>
							<ul class="actions special">
								<li><a href="https://github.com/NonyeJ/Google-Stocks-Time-Series-Forecasting-with-SARIMA-Model" class="button large">View Project</a></li>
							</ul>
						</article>		
						<!-- Featured Post -->
						<article class="post featured">
							<header class="major">
								<h2><a href="https://github.com/NonyeJ/Customer-Churn-Prediction">Data Exploratory Analysis with Python</h2>(Visualization: Matplotlib,Seaborn. Lib: Pandas)</a></a>
								    <p>Our client is a major gas and electricity utility that supplies to corporate, SME (Small & Medium Enterprise), and residential customers. The power-liberalization of the energy market in Europe has led to significant customer churn, especially in the SME segment. They want to diagnose the source of churning SME customers.
									A fair hypothesis is that price changes affect customer churn. Therefore, it is helpful to know which customers are more (or less) likely to churn at their current price, for which a good predictive model could be useful.
									Moreover, for those customers that are at risk of churning, a discount might incentivize them to stay with our client. The head of the SME division is considering a 20% discount that is considered large enough to dissuade almost anyone from churning (especially those for whom price is the primary concern).
									An initial team meeting was held to discuss various hypotheses, including churn due to price sensitivity. Deeper exploration is required on the hypothesis that the churn is driven by the customers’ price sensitivities.
									The client plans to use the predictive model on the 1st working day of every month to indicate to which customers the 20% discount should be offered.
									We would need to fomulate the hypothesis as a data science problem and lay out the major steps needed to test this hypothesis. Communicate your thoughts and findings to the client, focusing on the data that we would need from the client and the analytical models we would use to test such a hypothesis.<p>
							</header>
							<a href="https://github.com/NonyeJ/Customer-Churn-Prediction" class="image main"><img src="images/Churn.jpg" alt="" /></a>
							<ul class="actions special">
								<li><a href="https://github.com/NonyeJ/Customer-Churn-Prediction" class="button large">View Project</a></li>
							</ul>
						</article>	
						<!-- Featured Post -->
						<article class="post featured">
							<header class="major">
								<h2><a href="https://github.com/NonyeJ/Data-Cleaning-using-SQL">Data Cleaning with SQL</a></h2>
								<p>Data cleaning is a pertininet part of end to end data analysis process. SQL, in my opinion is a great tool. Apt, concise. The quality of the data we use determines the quality of the results and insights we get. Many professionals believe that we should dedicate more time to preparing and cleaning the data rather than other processes like EDA, ML, and others. Otherwise, we could finish with a bunch of inaccurate output.
									In this project I drive a cleaning data process to prepare data for analysis by modifying incomplete data, removing irrelevant and duplicated rows, splitting addresses, and modifying improperly formatted data.						
									Data cleaning is not about erasing information to simplify the dataset, but rather finding a way to maximize the accuracy of the collected data.
									Let’s go over cleaning techniques with a Housing dataset. It has 56K+ rows. Let’s get started!.<p>
							</header>
							<a href="https://github.com/NonyeJ/Data-Cleaning-using-SQL" class="image main"><img src="images/housing.jpg" alt="" /></a>
							<ul class="actions special">
								<li><a href="https://github.com/NonyeJ/Data-Cleaning-using-SQL" class="button large">View Project</a></li>
							</ul>
						</article>	
						<!-- Posts -->
							<section class="posts">
								<article>
									<header>
									<h2><a href="https://github.com/NonyeJ/Data-Exploration-using-SQL-for-case-study-Covid-19">Data Exploration in Structured Query Language<br />
										</a></h2>
									</header>
									<a href="https://github.com/NonyeJ/Data-Exploration-using-SQL-for-case-study-Covid-19" class="image fit"><img src="images/covid%2019.jpg" alt="" /></a>
									<p>Covid-19 was tough. It's the first pandemic I have ever witnessed and my world turned 360. This project is a simple data exploration excercise using Structured Query Language with real data sets from the Covid-19 pandemic. I do intend on working more with this data because the dataset is extensive. On Data exploration and aggregation, these are two significant aspects of data analysis while processing with transactional data stored in SQL Server for statistical inferences. For data exploration using data science languages like SQL, data often needs to be filtered, re-ordered, transformed, aggregated and visualized. There are many possibilities for achieving these functionalities.</p>
									<ul class="actions special">
										<li><a href="https://github.com/NonyeJ/Data-Exploration-using-SQL-for-case-study-Covid-19" class="button">View Project</a></li>
									</ul>
								</article>
								<article>
									<header>
										<section class="posts">
											<article>
												<header>
												<h2><a href="https://github.com/NonyeJ/Web-scraping">Web Scraping with Python (BeautifulSoup Lib)<br />
													</a></h2>
												</header>
												<a href="https://github.com/NonyeJ/Web-scraping" class="image fit"><img src="images/webscarping.jpg" alt="" /></a>
												<p>Web scraping (or data scraping) is a technique used to collect content and data from the internet. This data is usually saved in a local file so that it can be manipulated and analyzed as needed. If you’ve ever copied and pasted content from a website into an Excel spreadsheet, this is essentially what web scraping is, but on a very small scale.
													However, when people refer to ‘web scrapers,’ they’re usually talking about software applications. Web scraping applications (or ‘bots’) are programmed to visit websites, grab the relevant pages and extract useful information. By automating this process, these bots can extract huge amounts of data in a very short time. SR:Careerfoundry</p>
												<ul class="actions special">
													<li><a href="https://github.com/NonyeJ/Web-scraping" class="button">View Project</a></li>
												</ul>
											</article>
											<article>
												<header>
										
										<h2><a href="#">Data Visualization with Tableau & Power BI<br />
										</a></h2>
									</header>
									<a href="#" class="image fit"><img src="images/COMING_1.jpg" alt="" /></a>
									<p>The analyst is currently cooking new visualizations. Check back soon!</p>
									<ul class="actions special">
										<li><a href="#" class="button">Coming Soon!</a></li>
									</ul>
																	<header>
									<h2><a href="#">Correlation in Python</a></h2>
									</header>
									<a href="#" class="image fit"><img src="images/COMING_1.jpg" alt="" /></a>
									<p>Currently writing multiple lines of code using python. Please check in soon</p>
									<ul class="actions special">
										<li><a href="#" class="button">Coming soon!</a></li>
									</ul>
								</article>
								<article>
									
						<!-- Footer -->
							<footer>
								<div class="pagination">
									<!--<a href="#" class="previous">Prev</a>-->
									<a href="#" class="page active">1</a>
									<a href="#" class="page">2</a>
									<a href="#" class="page">3</a>
									<span class="extra">&hellip;</span>
									<a href="#" class="page">8</a>
									<a href="#" class="page">9</a>
									<a href="#" class="page">10</a>
									<a href="#" class="next">Next</a>
								</div>
							</footer>

					</div>

				Footer
					<footer id="footer">
						<section>
							<form method="post" action="#">
								<div class="fields">
									<div class="field">
										<label for="name">Name</label>
										<input type="text" name="name" id="name" />
									</div>
									<div class="field">
										<label for="email">Email</label>
										<input type="text" name="email" id="email" />
									</div>
									<div class="field">
										<label for="message">Message</label>
										<textarea name="message" id="message" rows="3"></textarea>
									</div>
								</div>
								<ul class="actions">
									<li><input type="submit" value="Send Message" /></li>
								</ul>
							</form>
						</section>
						<section class="split contact">
							<section class="alt">
								<h3>Address</h3>
								<p>Nigeria<br />
								</p>
							</section>
								
							<section>
								<h3>Email</h3>
								<p><a href="#">contactnonye@gmail.com</a></p>
							</section>
							<section>
								<h3>Social</h3>
								<ul class="icons alt">
									<li><a href="https://twitter.com/_NonyeOJ?t=XKpP13SXwC8lIZ2opfB1tQ&amp;s=03" class="icon brands alt fa-twitter"><span class="label">Twitter</span></a></li>
									<li><a href="#" class="icon brands alt fa-facebook-f"><span class="label">Facebook</span></a></li>
									<li><a href="#" class="icon brands alt fa-instagram"><span class="label">Instagram</span></a></li>
									<li><a href="https://github.com/NonyeJ" class="icon brands alt fa-github"><span class="label">GitHub</span></a></li>
								</ul>
							</section>
						</section>
					</footer>

				<!-- Copyright -->
					<div id="copyright">
						<ul><li>&copy; Untitled</li><li>Design: <a href="https://html5up.net/">HTML5 UP</a></li></ul>
					</div>

			</div>

		<!-- Scripts -->
			<script src="assets/js/jquery.min.js"></script>
			<script src="assets/js/jquery.scrollex.min.js"></script>
			<script src="assets/js/jquery.scrolly.min.js"></script>
			<script src="assets/js/browser.min.js"></script>
			<script src="assets/js/breakpoints.min.js"></script>
			<script src="assets/js/util.js"></script>
			<script src="assets/js/main.js"></script>

	</body>

<!-- Mirrored from nonyej.github.io/ by HTTrack Website Copier/3.x [XR&CO'2014], Tue, 02 May 2023 21:06:03 GMT -->
</html>
